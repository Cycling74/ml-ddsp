#pragma once

// @generated by tools/codegen/gen.py from FunctionalInverses.h

#include <ATen/Tensor.h>

namespace at {
namespace functionalization {

struct FunctionalInverses {

static at::Tensor _fw_primal_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t level);
static at::Tensor _make_dual_inverse(const at::Tensor & base, const at::Tensor & mutated_view, const at::Tensor & tangent, int64_t level);
static at::Tensor view_as_real_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor view_as_complex_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor _conj_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor _neg_view_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor as_strided_inverse(const at::Tensor & base, const at::Tensor & mutated_view, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset);
static at::Tensor _sparse_broadcast_to_inverse(const at::Tensor & base, const at::Tensor & mutated_view, at::IntArrayRef size);
static at::Tensor diagonal_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t offset, int64_t dim1, int64_t dim2);
static at::Tensor expand_inverse(const at::Tensor & base, const at::Tensor & mutated_view, at::IntArrayRef size, bool implicit);
static at::Tensor permute_inverse(const at::Tensor & base, const at::Tensor & mutated_view, at::IntArrayRef dims);
static at::Tensor _reshape_alias_inverse(const at::Tensor & base, const at::Tensor & mutated_view, at::IntArrayRef size, at::IntArrayRef stride);
static at::Tensor select_int_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t dim, int64_t index);
static at::Tensor detach_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor slice_Tensor_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t dim, c10::optional<int64_t> start, c10::optional<int64_t> end, int64_t step);
static at::Tensor split_Tensor_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t mutated_view_idx, int64_t split_size, int64_t dim);
static at::Tensor split_with_sizes_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t mutated_view_idx, at::IntArrayRef split_sizes, int64_t dim);
static at::Tensor squeeze_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor squeeze_dim_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t dim);
static at::Tensor t_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor transpose_int_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t dim0, int64_t dim1);
static at::Tensor unsqueeze_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t dim);
static at::Tensor _indices_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor _values_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor indices_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor values_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor crow_indices_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor col_indices_inverse(const at::Tensor & base, const at::Tensor & mutated_view);
static at::Tensor unbind_int_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t mutated_view_idx, int64_t dim);
static at::Tensor view_inverse(const at::Tensor & base, const at::Tensor & mutated_view, at::IntArrayRef size);
static at::Tensor view_dtype_inverse(const at::Tensor & base, const at::Tensor & mutated_view, at::ScalarType dtype);
static at::Tensor unfold_inverse(const at::Tensor & base, const at::Tensor & mutated_view, int64_t dimension, int64_t size, int64_t step);
static at::Tensor alias_inverse(const at::Tensor & base, const at::Tensor & mutated_view);

};
}
}
